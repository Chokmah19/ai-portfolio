# Week 1 - Google AI Essentials

## ✅ 本週目標
- 完成 Google AI Essentials 課程
- 建立 TensorFlow 環境

## 📅 本週任務紀錄
### Google AI Essentials
- 什麼是機器學習？  
ML是AI的分支，專注於開發可分析資料以做出決策或預測的電腦程式
    


#### 技術術語 
- 監督式 vs 非監督式學習  
    監督式學習：使用標記 (labeled) 訓練集訓練模型。標籤訓練集包含標籤或標記的資料，這些標註為資料提供上下文情境及意義。監督式學習通常用在有特定輸出的情況。  
非監督式學習：使用未標記 (unlabeled) 訓練集訓練模型。非監督式學習用在無特定輸出的情況，以找出資料中的模式。
- AI Tool and AI Model  - AI Tool：一種由 AI 驅動的軟體，可自動執行或協助使用者完成各種任務。  
AI Model：一種基於資料集訓練以識別模式並執行特定任務的電腦程式。
- shot  
    在提示工程中，“shot” 一詞通常用作“example”一詞的同義詞。 根據提供給 LLM 的範例數量，提示技術有不同的名稱。Zero-shot prompting 是一種在提示中提供示例的技術，而 one-shot prompting 提供一個示例，而 Few-shot prompting 是一種在提示中提供兩個或多個示例的技術
- System bias(系統性偏誤)  
    系統性偏誤是機構維護的傾向對某些結果或群體有利或不利。
社會體系中存在系統性偏誤如醫療保健、法律、教育、政治等等。
- Data bias(數據偏誤)  
    數據偏誤是指系統性錯誤或偏見導致資訊不公平或不準確，從而產生帶有偏誤的結果的情況。
- Drift(漂移)  
    漂移是指人工智慧模型預測準確度的下降，這是由於訓練資料未反映隨時間推移而發生的變化。這通常是由**知識截止(knowledge cutoff)**引起的，即模型在特定時間點進行訓練，因此它不具備該日期之後事件或資訊的任何知識。 

#### What's AI
- 人工智慧模型是價值負載(用來形容某事物或某概念帶有強烈的個人價值觀或情感色彩，使其並非完全客觀或中立。 簡單來說，就是「帶有價值判斷的」。)的。人工智慧工具本質上並不是價值中立的。

#### AI的風險與危害
- 分配傷害  
    當人工智慧系統的使用或行為在影響人類福祉的領域中剝奪機會、資源或資訊時發生的不法行為
- 服務品質損害  
    人工智慧工具根據其身分對某些人群表現不佳的情況
- 表徵性傷害  
    人工智慧工具強化社會群體基於身分的從屬關係
- 社會系統危害  
    由於人工智慧工具的開發或使用而產生的宏觀社會影響，會擴大現有的階級、權力或特權差距，或造成身體傷害 (Like deepfake)
- 人際傷害  
    利用科技對某些人造成不利影響，進而對他們與他人的關係產生負面影響，或導致他們喪失自我意識和自主性

## 💡 學習心得
- 瞭解 LLM（大型語言模型）如何運作
- 會設計有邏輯、有目標的 Prompt
- 認識 AI 在日常生活、職場的潛力與風險
