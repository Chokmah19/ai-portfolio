# Week 1-2 - Google AI note

## ✅ week1-2 主要目標
- 完成 Google AI Essentials 課程
- 完成 Prompting Essentials 課程

## 📅 Week1-2 任務紀錄
### Google AI Essentials & Prompting Essentials

### What's AI
- 人工智慧模型是價值負載(用來形容某事物或某概念帶有強烈的個人價值觀或情感色彩，使其並非完全客觀或中立。 簡單來說，就是「帶有價值判斷的」。)的。人工智慧工具本質上並不是價值中立的。
- 什麼是機器學習？  
ML 是 AI 的分支，專注於開發可分析資料以做出決策或預測的電腦程式

### AI的風險與危害
- 分配傷害  
    當人工智慧系統的使用或行為在影響人類福祉的領域中剝奪機會、資源或資訊時發生的不法行為
- 服務品質損害  
    人工智慧工具根據其身分對某些人群表現不佳的情況
- 表徵性傷害  
    人工智慧工具強化社會群體基於身分的從屬關係
- 社會系統危害  
    由於人工智慧工具的開發或使用而產生的宏觀社會影響，會擴大現有的階級、權力或特權差距，或造成身體傷害 (Like deepfake)
- 人際傷害  
    利用科技對某些人造成不利影響，進而對他們與他人的關係產生負面影響，或導致他們喪失自我意識和自主性

### LLM sampling parameters
- 調整模型的取樣參數以影響選擇輸出的概率，生成的文字風格和品質。採樣參數是影響此過程的護欄，允許您擴展或限制生成 AI 工具在創建其輸出時從中選擇的選項池。以下參數用以控制文字生成過程中的**隨機性**和**創造性**([ref.](https://blog.miniasp.com/post/2024/05/21/LLM-Temperature-Top-P-Nucleus-Sampling-Top-K))
- Temperature  
    決定該池中這些選項的概率的採樣參數稱為溫度。
- Top-K  
    決定了生成式 AI 可以選擇的響應數量。top-k 值設置token的總數（基本資訊單位），生成式 AI 工具從中選擇其輸出，精確地獲得所需的結果。
- Top-P  
    使用總組合概率進一步細化該池。每個token的概率分數在 0 到 1.0 之間，量化了生成式 AI 在其回應中隨機選擇它的機率。

    - Temperature 控制整體的創造性，Top-P 和 Top-K 則提供更精細的控制。
    - Top-P 根據累積機率動態調整選擇範圍，Top-K 根據排名設定固定的 Tokens 選擇數量。
    - 應用場景  
      文本生成： Top-K 可以控制模型生成的文本的多樣性，而 Top-P 可以控制文本的流暢度。
      機器翻譯： Top-K 和 Top-P 可以幫助模型選擇最有可能的翻譯。
      問答系統： Top-K 和 Top-P 可以幫助模型選擇最有可能的答案。

### 技術術語 
- AI Tool and AI Model
    - AI Tool：一種由 AI 驅動的軟體，可自動執行或協助使用者完成各種任務。
    - AI Model：一種基於資料集訓練以識別模式並執行特定任務的電腦程式。
- 監督式 vs 非監督式學習
    - 監督式學習：使用標記 (labeled) 訓練集訓練模型。標籤訓練集包含標籤或標記的資料，這些標註為資料提供上下文情境及意義。監督式學習通常用在有特定輸出的情況。
    - 非監督式學習：使用未標記 (unlabeled) 訓練集訓練模型。非監督式學習用在無特定輸出的情況，以找出資料中的模式。
- Prompt  
    提示是向生成式 AI 工具提供具體指令以接收新資訊或實現任務預期結果的過程。
- Shot  
    在提示工程中，“shot” 一詞通常用作“example”一詞的同義詞。 根據提供給 LLM 的範例數量，提示技術有不同的名稱。Zero-shot prompting 是一種在提示中提供示例的技術，而 one-shot prompting 提供一個示例，而 Few-shot prompting 是一種在提示中提供兩個或多個示例的技術(給幾個範例會讓AI回應更加準確)
- System bias(系統性偏誤)  
    系統性偏誤是機構維護的傾向對某些結果或群體有利或不利。
社會體系中存在系統性偏誤如醫療保健、法律、教育、政治等等。
- Data bias(數據偏誤)  
    數據偏誤是指系統性錯誤或偏見導致資訊不公平或不準確，從而產生帶有偏誤的結果的情況。
- Drift(漂移)  
    漂移是指人工智慧模型預測準確度的下降，這是由於訓練資料未反映隨時間推移而發生的變化。這通常是由**知識截止(knowledge cutoff)**引起的，即模型在特定時間點進行訓練，因此它不具備該日期之後事件或資訊的任何知識。 
- Multimodal prompting  
    使用不同類型的媒體來提示生成式 AI 工具，例如輸入圖像和文字，或音訊和文本。模態是不同類型的格式，如文本、圖像或音訊，可用於指示生成式 AI 工具。因此，多模態提示是指在同一個提示中使用多個模態。
- Hallucinations  
    當生成式 AI 工具提供錯誤資訊的輸出時，稱為幻覺
    - 事實核查和交叉引用
    - 使用更清晰或更詳細的語言

### Prompt skill
- 5-step prompt framework
    - Task        -> 角色、格式
    - Context     -> 上下文或必要的詳細資訊
    - References  -> 可提供生成式 AI 工作範例，這可能意味著要求它學習特定參考資料的語氣、風格或長度。提供多個參考資料也被稱為few shot prompting.
    - Evaluate    -> 在使用任何 AI 生成的資訊、文本或材料之前，先嚴格評估輸出是否準確、公正、相關且一致
    - Iterate     -> 反覆運算=不斷改進。評估輸出並確定沒有得到所需的內容，則可以通過添加更多資訊或調整提示來重試，**A**lways **B**e **I**terating.**(ABI)**
        - 重新訪問提示框架：確保提示清楚地說明想要的任務，並包括特定的角色和格式、充足的上下文並提供相關參考。
        - 將提示分成更短的句子：不要將所有內容都打包到一個複雜而冗長的提示中，而是在單獨的提示中解決每個單獨的步驟。
        - 調整措辭或切換到類似的任務：改變語言，以不同的方式解釋意思。
        - 引入約束：通過向提示添加約束或限制來集中生成 AI 工具的輸出。當您在提示中為特定類別、長度、格式或其他詳細資訊設置邊界時，可以讓該工具提供更精確的輸出。
    - **Thoughtfully Create Really Excellent Inputs -> 深思熟慮地創造真正出色的輸入**
- prompt chaining
    - Chain-of-thought(CoT)
        - 要求生成式 AI 工具解釋其推理或逐步描述它是如何獲得特定結果的。此方法可以瞭解生成式 AI 工具的推理方法，可根據其輸出做出更好的決策。
    - Tree-of-thought(ToT)
        - 是一種一次探索多種可能的解決方案的技術，可幫助使用者找到最有效的方法。
- Meta-prompting
    - Prompt generation strategies  
        從頭開始設計提示
    - Prompt refinement strategies  
        微調已設計的提示

## 💡 學習心得
- 瞭解 LLM（大型語言模型）如何運作
- 認識 AI 在日常生活、職場的潛力與風險
- 學會設計各種目標導向的Prompt，如何設計Prompt框架，提高生產力及效率。像是這份進修計劃就是我經由 Iterate 不斷改進產出的，已有成功實踐 5-step prompt framework
